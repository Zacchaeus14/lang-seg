{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a311212-8e3d-43bc-bd94-962de116b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import functools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as torch_transforms\n",
    "import encoding.datasets as enc_ds\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b298dd-65ec-4809-918f-7176971e91e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coco': functools.partial(<function get_dataset at 0x7f9a90b29c10>, 'coco'),\n",
       " 'ade20k': functools.partial(<function get_dataset at 0x7f9a90b29c10>, 'ade20k'),\n",
       " 'pascal_voc': functools.partial(<function get_dataset at 0x7f9a90b29c10>, 'pascal_voc'),\n",
       " 'pascal_aug': functools.partial(<function get_dataset at 0x7f9a90b29c10>, 'pascal_aug'),\n",
       " 'pcontext': functools.partial(<function get_dataset at 0x7f9a90b29c10>, 'pcontext'),\n",
       " 'citys': functools.partial(<function get_dataset at 0x7f9a90b29c10>, 'citys')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_datasets = {\n",
    "    x: functools.partial(enc_ds.get_dataset, x)\n",
    "    for x in [\"coco\", \"ade20k\", \"pascal_voc\", \"pascal_aug\", \"pcontext\", \"citys\"]\n",
    "}\n",
    "encoding_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6efcec0f-e322-4a98-9b74-21b8c49c2555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseDataset: base_size 520, crop_size 480\n",
      "len(img_paths): 20210\n"
     ]
    }
   ],
   "source": [
    "norm_mean= [0.5, 0.5, 0.5]\n",
    "norm_std = [0.5, 0.5, 0.5]\n",
    "train_transform = [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(norm_mean, norm_std),\n",
    "        ]\n",
    "train_transform = transforms.Compose(train_transform)\n",
    "kwargs = {'root': '../datasets/', \n",
    "          'split': 'train', \n",
    "          'mode': 'train', \n",
    "          'transform': train_transform, \n",
    "          'base_size': 520,\n",
    "          'crop_size': 480}\n",
    "name = 'ade20k'\n",
    "dataset = encoding_datasets[name.lower()](**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aed978b-09a3-4e61-8143-1ef81b3e857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ...,  -1,  -1,  -1],\n",
       "        [  0, 134, 134,  ...,  -1,  -1,  -1],\n",
       "        [  0, 134, 134,  ...,  -1,  -1,  -1],\n",
       "        ...,\n",
       "        [ -1,  -1,  -1,  ...,  -1,  -1,  -1],\n",
       "        [ -1,  -1,  -1,  ...,  -1,  -1,  -1],\n",
       "        [ -1,  -1,  -1,  ...,  -1,  -1,  -1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56cb86-2f1f-4872-989d-59e6eee72e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
